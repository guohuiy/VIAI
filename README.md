# V8-AI - é«˜æ€§èƒ½è®¡ç®—æœºè§†è§‰éƒ¨ç½²å¹³å°

V8-AI æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½è®¡ç®—æœºè§†è§‰éƒ¨ç½²å¹³å°ï¼Œé‡‡ç”¨æ’ä»¶åŒ–æ¶æ„è®¾è®¡ï¼Œæ”¯æŒå¤šåç«¯æ¨ç†å¼•æ“ï¼Œä¸“æ³¨äºè®¡ç®—æœºè§†è§‰ç®—æ³•çš„é«˜æ€§èƒ½éƒ¨ç½²ä¸ä¼˜åŒ–ã€‚

## é¡¹ç›®ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½æ¨ç†**: æ”¯æŒ TensorRTã€ONNX Runtimeã€OpenVINOã€NCNN å¤šåç«¯
- ğŸ”Œ **æ’ä»¶åŒ–æ¶æ„**: åŠ¨æ€åŠ è½½å’Œç®¡ç†è®¡ç®—æœºè§†è§‰ç®—æ³•æ’ä»¶
- ğŸ’¾ **æ™ºèƒ½å†…å­˜ç®¡ç†**: é’ˆå¯¹ 4GB æ˜¾å­˜ç¯å¢ƒä¼˜åŒ–çš„å†…å­˜æ± ç³»ç»Ÿ
- ğŸ§µ **å¤šçº¿ç¨‹ä¼˜åŒ–**: SIMD æŒ‡ä»¤é›†ä¼˜åŒ–å’Œå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
- ğŸ“Š **æ€§èƒ½ç›‘æ§**: å®æ—¶æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åˆ†æ
- ğŸ³ **å®¹å™¨åŒ–éƒ¨ç½²**: æ”¯æŒ Docker å®¹å™¨åŒ–éƒ¨ç½²

## ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   åº”ç”¨å±‚ (Application Layer)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               æ’ä»¶ç®¡ç†å™¨ (Plugin Manager)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             ç»Ÿä¸€æ¨ç†æ¥å£ (Inference Engine)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             å¤šåç«¯æ¨ç†å¼•æ“ (Backend Engines)        â”‚
â”‚         TensorRT â”‚ ONNX Runtime â”‚ OpenVINO â”‚ NCNN  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               ç¡¬ä»¶æŠ½è±¡å±‚ (HAL)                     â”‚
â”‚         GPU (CUDA) â”‚ CPU (SIMD) â”‚ å†…å­˜ç®¡ç†         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Windows 10/11, Linux, macOS
- **CUDA**: 11.8+ (NVIDIA GPU)
- **OpenCV**: 4.8+
- **CMake**: 3.20+
- **ç¼–è¯‘å™¨**: MSVC 2022, GCC 9+, Clang 12+

### æ„å»ºé¡¹ç›®

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd V8-AI

# åˆ›å»ºæ„å»ºç›®å½•
mkdir build && cd build

# é…ç½®æ„å»º
cmake -DCMAKE_BUILD_TYPE=Release ..

# ç¼–è¯‘
make -j$(nproc)

# è¿è¡Œ
./v8_ai
```

### Docker éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t v8-ai:latest .

# è¿è¡Œå®¹å™¨
docker run --gpus all -v ./models:/app/models -v ./plugins:/app/plugins v8-ai:latest
```

## æ’ä»¶å¼€å‘

### åˆ›å»ºè‡ªå®šä¹‰æ’ä»¶

```cpp
#include "v8_core/plugin_interface.h"

class CustomDetector : public IPlugin {
public:
    bool initialize(const PluginConfig& config) override {
        // åˆå§‹åŒ–é€»è¾‘
        return true;
    }
    
    PluginResult execute(const PluginInput& input, 
                       PluginOutput& output) override {
        // è‡ªå®šä¹‰å¤„ç†é€»è¾‘
        return PluginResult::Success;
    }
};

// æ³¨å†Œæ’ä»¶
REGISTER_PLUGIN("custom_detector", CustomDetector);
```

### æ’ä»¶é…ç½®

```yaml
# config.yaml
plugins:
  - name: "yolov8_detector"
    type: "detector"
    model: "models/yolov8n.onnx"
    backend: "tensorrt"
    precision: "fp16"
  
  - name: "sam_segmenter"
    type: "segmenter"
    model: "models/sam_base.onnx"
    backend: "onnxruntime"
```

## æ€§èƒ½åŸºå‡†

| æ¨¡å‹ | åç«¯ | å»¶è¿Ÿ (ms) | æ˜¾å­˜å ç”¨ | FPS |
|------|------|-----------|----------|-----|
| YOLOv8n | TensorRT | 4.2ms | 1.2GB | 238 |
| SAM-Base | ONNX Runtime | 152ms | 3.2GB | 6.5 |
| PaddleOCR | TensorRT | 8.5ms | 0.8GB | 117 |

## é¡¹ç›®ç»“æ„

```
V8-AI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ plugin_manager.h/cpp    # æ’ä»¶ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ inference_engine.h/cpp  # æ¨ç†å¼•æ“æ¥å£
â”‚   â”‚   â””â”€â”€ memory_pool.h/cpp       # å†…å­˜æ± ç®¡ç†
â”‚   â”œâ”€â”€ backends/          # æ¨ç†åç«¯
â”‚   â”‚   â”œâ”€â”€ tensorrt/      # TensorRT åç«¯
â”‚   â”‚   â”œâ”€â”€ onnxruntime/   # ONNX Runtime åç«¯
â”‚   â”‚   â”œâ”€â”€ openvino/      # OpenVINO åç«¯
â”‚   â”‚   â””â”€â”€ ncnn/          # NCNN åç«¯
â”‚   â”œâ”€â”€ plugins/           # æ’ä»¶å®ç°
â”‚   â”‚   â”œâ”€â”€ detectors/     # æ£€æµ‹å™¨æ’ä»¶
â”‚   â”‚   â”œâ”€â”€ segmenters/    # åˆ†å‰²å™¨æ’ä»¶
â”‚   â”‚   â””â”€â”€ classifiers/   # åˆ†ç±»å™¨æ’ä»¶
â”‚   â””â”€â”€ utils/             # å·¥å…·ç±»
â”œâ”€â”€ include/               # å¤´æ–‡ä»¶
â”œâ”€â”€ models/                # æ¨¡å‹æ–‡ä»¶
â”œâ”€â”€ plugins/               # æ’ä»¶æ–‡ä»¶
â”œâ”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â””â”€â”€ CMakeLists.txt         # æ„å»ºé…ç½®
```

## è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## è”ç³»æˆ‘ä»¬

- é¡¹ç›®ä¸»é¡µ: [https://github.com/your-org/v8-ai](https://github.com/your-org/v8-ai)
- é‚®ç®±: contact@v8-ai.com
- æ–‡æ¡£: [docs/](docs/)

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2026-02-04)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- æ”¯æŒå¤šåç«¯æ¨ç†å¼•æ“
- æ’ä»¶åŒ–æ¶æ„è®¾è®¡
- å†…å­˜ä¼˜åŒ–ç³»ç»Ÿ
- æ€§èƒ½ç›‘æ§åŠŸèƒ½